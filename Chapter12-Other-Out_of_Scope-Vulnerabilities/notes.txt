Chapter 12. Other (Out of Scope) Vulnerabilities

We've covered a lot about what you should look for—the structure of vulnerabilities, and how to test for them in both programmatic and manual ways.

It seems unimportant to talk about what you shouldn't look for—if you don't care about it, you'll just ignore it, right? But there are several common findings and false positives that you'll see being spit out by scanners, passive analysis tools, extensions, and command-line logs again and again. It's useful to have an idea of what vulnerabilities companies are not interested in so that you can both avoid wasting your time submitting doomed bug reports and configure your tools to report less noise to you in the first place.

The common theme for most of the vulnerabilities we'll cover here are that they don't have a clear path to exploitation. They either only affect the attacker, require other (more serious) vulnerabilities to be present before they can be exploited, or in the case of leaked information, don't give an attacker any actionable information.

This chapter will cover what vulnerabilities companies often exclude from bug bounty programs, including how they work and why they're often not covered, and some of the common themes in what excludes a bug from reward consideration.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
DoS/DDoS – The Denial-of-Service Problem

Denial-of-Service (DoS) and Distributed Denial-of-Service (DDoS) are familiar strains of cyberattack to anyone who follows
security news. Flooding a target with traffic indistinguishable from a legitimate surge of visitors remains a popular method for
either taking down or crippling a web property, especially when combined with amplification attacks caused by hijacking other
servers, spoofing connected services, or taking advantage of an internal performance flaw or bottleneck.

Defending against DDoS attacks requires an entire proactive security architecture, redistributing the load across different
networks and throttling/isolating malicious sources of traffic

The exception is when a DoS/DDoS attack is more effective because it can leverage a security flaw that exists on the victim
network. If, as a security researcher, you come across, for example, an unsecured NTP server that could be hijacked to
amplify a DDoS attack, you should certainly report it as a vulnerability that could be used to threaten either you or
another bystander's network.
Note

You should not try to validate any vulnerabilities like this by leveraging them for increased bot traffic, even if you think it
falls below the threshold of something that could damage the target's infrastructure. The fact that DDoS prohibitions are so
common is a sign of how seriously they're taken by bounty program operators.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Sandboxed and Self-XSS – Low-Threat XSS Varieties

Self-XSS is a variety of XSS that relies heavily on social engineering, which is the primary reason it is excluded from most
bug bounty programs.
Sandboxed XSS, a similar term for a related strain, is typically used to describe an XSS vulnerability that happens on a machine
isolated from sensitive user data or operations.

Since Self-XSS refers to the specific phenomenon of executing code within your browser environment to make yourself vulnerable
to an XSS attack, it also means that your XSS bug is isolated in terms of what information it can access.

For Self-XSS to take place, the attacker must get the victim to execute code within the browser context.

That execution is what makes the victim susceptible to further exploitation by the attacker.

A simple example of self-XSS in action would be as follows:

    An attacker advertises a hacking-kit-in-a-box - H4x0rs l18e 1337! or whatever the kids say these days.
    All you have to do is copy this code snippet and paste it into the developer console of your browser.

    You, beautifully gullible, happily copy the code and paste it into your console, imagining the terror of your digital wrath.

    Instead of hacking someone else, the code you pasted into your console just exposed you to hackers.

    Any sensitive session cookies or information available in your browser is now the property of a shadowy cabal of cyberanarchists.

For an example of this in action, check out the link in the Further reading section for a write-up of a very similar scam
that got passed around on Facebook a few years ago: the post (also) encouraged you to follow the directions to hack any
Facebook account, (also) asking you to copy and execute code in your developer console, and (also) hacking you when you actually
complied.

Because this particular bug, like so many of these un-rewardable, almost-vulnerabilities, requires either action outside the
application context (a phone support worker initiating a change under the influence of social engineering) or other application-
based vulnerabilities to be present and ripe for exploitation, it falls outside the scope of most programs and is not eligible for a reward.

Even as companies write guides to avoiding these kinds of scams, they're limited in terms of the preventative action they can take: there's only so many ways to secure a house if the owner is intent on giving away their keys.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Non-Critical Data Leaks – What Companies Don’t Care About


In Chapter 8, Access Control and Security Through Obscurity, as part of our discussion about access control, security by
obscurity, and data leakage, we briefly covered different types of data that companies weren't interested in rewarding: usernames, descriptive-but-not-sensitive error messages,
different kinds of error codes, and so on.

Here are some other, specific examples about information that security researchers often report, but that companies very
rarely pay for.


Emails

    Emails are an item of information many people try to deny to bots and automated agents crawling their site.

    One typical strategy is encoding email links as HTML entities to make them harder to collect.
    That means you can hide an email such as  nessus@generalproducts.biz as the following entity code:

        nessus@generalproducts.biz

Unless the crawler is expecting to detect and decode entities as part of its scraping process, this little obfuscation trick can be surprisingly effective.

But if an email is exposed on a company site, it's usually meant to be a public-facing handle.

Submitting a bug report about support@company.com or even because you've deduced the employee email naming convention is
something like lastname.firstname@company.com doesn't meet the standard for a payout.

There are too many extra steps beyond simply enumerating a company's email username registry before the disclosure becomes a vulnerability.


HTTP Request Banners

    HTTP banners are an integral part of the protocol that stitches the entire web together.

    On common services, that might be privy to many different types of devices.
    They can include encoding data, device information, general information about the nature of the HTTP request, and other data.

All of that is to be expected as part of the service and doesn't constitute a leaked source of sensitive system information.

This includes both information contained in the present banners as well as "missing" security banners.


Known Public Files

    This is simple: some files are designed to be accessible! Reporting on the configuration or availability of  robots.txt, wp-uploads , or sitemap.xml isn't going to merit a payout—or probably even a response.


Missing HttpOnly Cookie Flags

    HttpOnly cookie flags are anti-XSS prevention devices.
    If a server-side process flags a cookie as HttpOnly, it can't be accessed client-side (when the browser attempts to
    read the cookie, it just returns an empty string).

    Every major browser supports HttpOnly cookies.
    But whatever their value, they are a safeguard, and their absence does not directly imply a vulnerability. If there's
    no additional XSS, there's no issue.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Other Common No-Payout Vulnerabilities

In addition to the larger categories of bugs that we've discussed that typically don't merit a payout, and keeping in
mind that these are in addition to previously-submitted vulnerabilities, which are ineligible for payout everywhere,
there are also a lot of one-offs and miscellaneous would-be vulnerabilities you should try to avoid submitting.

Weak or Easily Nypassed Captchas

    CAPTCHA (and their successor, reCAPTCHAs) are Google-administered Turing tests designed to block bot form
    submission spam by asking a bot to do things (sophisticated natural language detection, image pattern recognition,
    performing tasks on dynamic challenges, and so on) that your average bot can't do.

    Because they represent a third-party service whose security posture is managed by an outside company, most companies
    that host CAPTCHAs themselves won't reward any CAPTCHA-related bugs or vulnerabilities.


The HTTP OPTIONS Method Enabled

    HTTP supports a variety of requests outside the standard GET, PUT/PATCH, POST, and DELETE requests.

    OPTIONS is a diagnostic method that can enable debugging and stack trace data that can potentially be useful to an attacker.
    Although it increases your attack surface and is something you should definitely avoid as an application developer, having OPTIONS enabled is not a vulnerability per-se.
    Like other wannabe bugs that we've discussed, it requires too many extra steps in order to demonstrate a valid attack scenario.


BEAST (CVE-2011-3389) and Other SSL-Based Attacks

    The Browser Exploit Against SSL/TLS (BEAST) attack assumes a fair degree of client-side control, with the attacker able
    to inject packets in the browser's TLS stream by performing a Man-in-The-Middle (MiTM) attack, which then allows the
    attacker to guess the initialization vector involved and decrypt other information.

    As the security product company, Acunetix, notes in one of its blog posts about the attack:

        It’s worth noting that for the BEAST attack to succeed, an attacker must have reasonable control of the victim’s
        browser, in which case it's [sic] more probable that an easier attack vector is chosen.


This exemplifies a couple of themes common to our no-reward staple of would-be vulnerabilities: the vulnerability in
question is one that affects the actual TLS/SSL connection, which means it's the responsibility of the underlying tech, and
not just that particular implementation of it; it's also a bug that requires several other vulnerabilities to be exploited, meaning that if it's present, it's not the issue that should be
our greatest concern.
Both of these dynamics work to invalidate it and other SSL-based attacks as reportable submissions.


Brute Forcing Authentication Systems

    If an authentication system (a GUI form, an API request, or any other implementation or layer) doesn't lock a user out
    after a certain number of failed login attempts,
    it leaves itself open to being brute forced, with an attacker trying every possible combination of credentials
    until he/she is successful.
    Locking a user out after X failed attempts is a common security best practice, but missing that feature doesn't
    immediately make an application insecure.
    The amount of resources involved in brute forcing and the high level of noise it would make to any observing system
    engineer, means that, by itself, brute-force-ability isn't a compelling enough foundation for a severe attack scenario.

    Additionally, testing the efficacy of a brute force attack means making a brute force attack, which can deal serious
    damage to the target company's infrastructure and computing resources.


CSRF Logout

    Traditionally considered to be a security non-issue (and still not rewarded by many bounty programs), the ability for
    a cross-site request to forcefully log a user out is being reevaluated as a possible security threat by organizations
    like Detectify Labs,
    who have published a couple of different attack scenarios outlining when logout functionality being susceptible to CSRF is a problem (check the Further reading section for the link).
    Despite the constant reevaluation of the bug, it still often requires several extra steps to become a true vulnerability
    with a credible attack scenario, and is therefore not a priority for bug bounty programs.


Anonymous Form CSRF

    Another common CSRF-related vulnerability that doesn't often receive a payout is an anonymous form (for example, Contact Us) that is susceptible to CSRF.
    If an anonymous form is susceptible to CSRF, it means that an attacker could trick the victim into submitting it with different or modified fields.

    Taking the contact form as our example, this bug doesn't merit a payout because there's no relevant attack scenario
    that we can derive from it.
    Even if we submit the form with a different email address or message, it's not clear what damage that would do.

    For more mission-critical forms (filling out payment information, changing account settings, or authentication
    methods), we can come up with some bone-chilling scenarios, but if a form is anonymous, that usually means it's expected
    to receive a bunch of spam, and is isolated from important functions accordingly.



        This example drives home a general point we've been making (and will continue to make) throughout this book:
        attack scenarios modeling a critical attack are essential to making sure that your submission is rewarded.


Clickjacking and Clickjacking-Enabled Attacks

    Clickjacking is when an attacker hides a malicious link in a transparent or obscured link under a legitimate, safe, button so that users are tricked into following the black hat URL.

    Clickjacking is omitted from bounty programs because it requires that the company itself is use dark patterns
    (malicious UX/UI techniques), tricking users into following harmful links on a platform they control.

    Since any company actually doing that most certainly wouldn't advertise it, bounty programs aren't interested in
    paying out for a vulnerability that can otherwise only exist if a user modifies code on their own machine.
    That's why clickjacking (and vulnerabilities that can only occur via clickjacking) don't get rewarded.


Physical Testing Findings

    Sometimes, firms interested in rigorous security audits go several steps further than just hiring a team to test a
    website or probe a network—they pay for a researcher to test the physical security perimeter controlling access to their
    data center.
    This type of testing is most common in industries with strong compliance policies around access control—PCI
    compliance,
        for example, entails that you have taken certain
        physical security measures (ID cards required for access
        to the premises, limited access to actual server boxes,
        and so on) for safeguarding your infrastructure.

    Anything even close to physical testing is out-of-bounds for the type of work this book is concerned with.
    If you've identified a vulnerability that consists of you sneaking in through the company break room and messing with someone's unlocked laptop, that is not a vulnerability.
    That activity is very much out-of-scope and potentially legally actionable.


Outdated Browsers

    When you find a vulnerability that depends on an outdated browser for an attack vector, especially for a comparably
    ancient install (older than IE 8), it doesn't make sense for a company to reward it with a payout—outdated browsers
    aren't receiving security updates (and any fix the company might want to apply), after all.
    Even if the issue can be patched server-side, it makes no sense to carve out exceptions to an applicable end-of-life policy.


Server Information

    Although it's a valuable part of the discovery phase in any engagement, discovering the type of server or hosting
    service is not a bug.
    Obfuscation is nice, but superfluous, and basic public server data itself doesn't suggest a compelling attack chain
    worthy of a payout.


Rate-Limiting

    Rate-limiting might surprise you as something that has to be
    explicitly excluded in a program's out-of-scope
    vulnerabilities, but obviously rate-limiting (protecting
    your server from getting hosed by selectively throttling
    requests) is a feature, not a bug.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Summary

This chapter has covered different types of security flaws that typically don't rise to the level of a profitable vulnerability,
including DoS/DDoS, Self-XSS, and other types of attacks, as well as information that is commonly reported by scanners and
pentesting tools but that don't necessarily interest bug bounty program operators.
Along with various miscellaneous out-of-scope vulnerabilities, and an analysis of the common features that link these bugs
together (they require other exploits, they have limited reach, they require social engineering or attacks on third-party
services, and so on), you should have an understanding of not only what bugs don't get rewarded but why they aren't valuable.

Now, moving forward, you can tune your own workflow to lower the noise in your reporting, and build a pentesting regimen that
cuts down on time-wasting dead ends and focuses on the
vulnerabilities that matter.


~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Further Reading

You can find out more about some of the topics we have discussed in this chapter at:

    Facebook Self-XSS Scam: https://www.tomsguide.com/us/facebook-self-xss,news-19224.html
    GitHub DDoS Attack: https://www.theregister.co.uk/2018/03/05/worlds_biggest_ddos_attack_record_broken_after_just_five_days/
    TLS/SSL Vulnerability Attacks: https://www.acunetix.com/blog/articles/tls-vulnerabilities-attacks-final-part/
    Detectify Labs on CSRF Logouts: https://labs.detectify.com/2017/03/15/loginlogout-csrf-time-to-reconsider/
    Dark Patterns: https://darkpatterns.org/
